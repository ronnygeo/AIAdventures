{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TF-RecSys-Retreival-SingleTask.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GJljhKXlz1tU",
        "outputId": "7522cfd3-ec28-43d1-c21d-5b503a026b26"
      },
      "source": [
        "!pip install -q tensorflow-recommenders"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[?25l\r\u001b[K     |████▏                           | 10kB 23.5MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 20kB 23.3MB/s eta 0:00:01\r\u001b[K     |████████████▌                   | 30kB 28.3MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 40kB 30.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 51kB 32.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 61kB 35.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▎  | 71kB 29.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 81kB 10.1MB/s \n",
            "\u001b[?25h"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xZRCEV890D0u"
      },
      "source": [
        "from typing import Dict, Text\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import tensorflow.keras.layers as L\n",
        "\n",
        "import tensorflow_recommenders as tfrs"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wr4p-KLshtfl",
        "outputId": "f85a0de4-262e-429f-ea00-e9dee869cd78"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5b1MuBRp7v6m"
      },
      "source": [
        "This steam dataset was obtained from kaggle\n",
        "\n",
        "https://www.kaggle.com/tamber/steam-video-games/version/1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "eHXDp29ai82e",
        "outputId": "1fa2ca7c-1ad7-436f-de05-f920a164e970"
      },
      "source": [
        "data = pd.read_csv('/content/drive/My Drive/colab/data/steam-200k.csv', header=None).rename({0: \"user_id\", \n",
        "                                                                                             1: \"title\",\n",
        "                                                                                             2: \"action\",\n",
        "                                                                                             3: \"label\"}, axis=1)\n",
        "data.head()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user_id</th>\n",
              "      <th>title</th>\n",
              "      <th>action</th>\n",
              "      <th>label</th>\n",
              "      <th>4</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>151603712</td>\n",
              "      <td>The Elder Scrolls V Skyrim</td>\n",
              "      <td>purchase</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>151603712</td>\n",
              "      <td>The Elder Scrolls V Skyrim</td>\n",
              "      <td>play</td>\n",
              "      <td>273.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>151603712</td>\n",
              "      <td>Fallout 4</td>\n",
              "      <td>purchase</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>151603712</td>\n",
              "      <td>Fallout 4</td>\n",
              "      <td>play</td>\n",
              "      <td>87.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>151603712</td>\n",
              "      <td>Spore</td>\n",
              "      <td>purchase</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     user_id                       title    action  label  4\n",
              "0  151603712  The Elder Scrolls V Skyrim  purchase    1.0  0\n",
              "1  151603712  The Elder Scrolls V Skyrim      play  273.0  0\n",
              "2  151603712                   Fallout 4  purchase    1.0  0\n",
              "3  151603712                   Fallout 4      play   87.0  0\n",
              "4  151603712                       Spore  purchase    1.0  0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "6z5r82HfjGvi",
        "outputId": "30af5281-d37a-414c-c7c9-80f379d695a3"
      },
      "source": [
        "purchase_data = data[data[\"action\"] == 'purchase'][[\"user_id\",\"title\"]].drop_duplicates().astype(\"string\")\n",
        "purchase_data"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user_id</th>\n",
              "      <th>title</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>151603712</td>\n",
              "      <td>The Elder Scrolls V Skyrim</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>151603712</td>\n",
              "      <td>Fallout 4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>151603712</td>\n",
              "      <td>Spore</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>151603712</td>\n",
              "      <td>Fallout New Vegas</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>151603712</td>\n",
              "      <td>Left 4 Dead 2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>199990</th>\n",
              "      <td>128470551</td>\n",
              "      <td>Fallen Earth</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>199992</th>\n",
              "      <td>128470551</td>\n",
              "      <td>Magic Duels</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>199994</th>\n",
              "      <td>128470551</td>\n",
              "      <td>Titan Souls</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>199996</th>\n",
              "      <td>128470551</td>\n",
              "      <td>Grand Theft Auto Vice City</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>199998</th>\n",
              "      <td>128470551</td>\n",
              "      <td>RUSH</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>128804 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          user_id                       title\n",
              "0       151603712  The Elder Scrolls V Skyrim\n",
              "2       151603712                   Fallout 4\n",
              "4       151603712                       Spore\n",
              "6       151603712           Fallout New Vegas\n",
              "8       151603712               Left 4 Dead 2\n",
              "...           ...                         ...\n",
              "199990  128470551                Fallen Earth\n",
              "199992  128470551                 Magic Duels\n",
              "199994  128470551                 Titan Souls\n",
              "199996  128470551  Grand Theft Auto Vice City\n",
              "199998  128470551                        RUSH\n",
              "\n",
              "[128804 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rbb8CsMt2N75"
      },
      "source": [
        "members = tf.data.Dataset.from_tensors(tf.constant(purchase_data.user_id.unique()))\n",
        "movies = tf.data.Dataset.from_tensors(tf.constant(purchase_data.title.unique()))\n",
        "\n",
        "ratings = (tf.data.Dataset\n",
        "             .from_tensor_slices((tf.cast(purchase_data.user_id.values, tf.string), \n",
        "                                  tf.cast(purchase_data.title.values, tf.string)))\n",
        "              .map(lambda x1,x2: {\n",
        "                                  \"user_id\": x1,\n",
        "                                  \"movie_title\": x2\n",
        "                                }\n",
        "                   )\n",
        "              .shuffle(buffer_size=200000))\n",
        "\n",
        "train_ratings = ratings.take(100000)\n",
        "test_ratings = ratings.skip(100000).batch(8000)\n",
        "\n",
        "for row in test_ratings.batch(1).take(1):\n",
        "  print(row)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZYSRRwrewYU7"
      },
      "source": [
        "EMBEDDING_SIZE = 16\n",
        "MAX_TOKENS = 10_000"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rlfcHVTQjTYz"
      },
      "source": [
        "member_vocabulary = L.experimental.preprocessing.StringLookup()\n",
        "member_vocabulary.adapt(members)\n",
        "\n",
        "movie_titles_vocabulary = L.experimental.preprocessing.StringLookup(mask_token=None)\n",
        "movie_titles_vocabulary.adapt(movies)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BVGG2XNIwO8a"
      },
      "source": [
        "class MovieModel(tf.keras.Model):\n",
        "\n",
        "  def __init__(self, max_tokens=MAX_TOKENS):\n",
        "    super().__init__()\n",
        "\n",
        "    self.title_embedding = tf.keras.Sequential([\n",
        "        movie_titles_vocabulary,\n",
        "        tf.keras.layers.Embedding(movie_titles_vocabulary.vocab_size(), EMBEDDING_SIZE)\n",
        "    ])\n",
        "    self.title_text_embedding = tf.keras.Sequential([\n",
        "      tf.keras.layers.experimental.preprocessing.TextVectorization(max_tokens=max_tokens),\n",
        "      tf.keras.layers.Embedding(max_tokens, EMBEDDING_SIZE, mask_zero=True),\n",
        "      # We average the embedding of individual words to get one embedding vector\n",
        "      # per title.\n",
        "      tf.keras.layers.GlobalAveragePooling1D(),\n",
        "    ])\n",
        "\n",
        "  def call(self, inputs):\n",
        "    return tf.concat([\n",
        "        self.title_embedding(inputs[\"movie_title\"]),\n",
        "        self.title_text_embedding(inputs[\"movie_title\"]),\n",
        "    ], axis=1)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yfhAayIJ2zUn"
      },
      "source": [
        "# Define user and movie models.\n",
        "movie_model = MovieModel()\n",
        "movie_model.title_text_embedding.layers[0].adapt(\n",
        "    ratings.map(lambda x: x[\"movie_title\"]))\n",
        "\n",
        "user_model = tf.keras.Sequential([\n",
        "    member_vocabulary,\n",
        "    tf.keras.layers.Embedding(member_vocabulary.vocab_size(), EMBEDDING_SIZE*2)\n",
        "])\n",
        "\n",
        "metrics = tfrs.metrics.FactorizedTopK(\n",
        "  candidates=movies.map(lambda x: {\"movie_title\": x}).map(movie_model)\n",
        ")\n",
        "\n",
        "task = tfrs.tasks.Retrieval(\n",
        "  metrics=metrics\n",
        ")"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jg1hu-Kg2rKj"
      },
      "source": [
        "class MovielensModel(tfrs.Model):\n",
        "\n",
        "  def __init__(self, user_model, movie_model, task):\n",
        "    super().__init__()\n",
        "    self.movie_model: tf.keras.Model = movie_model\n",
        "    self.user_model: tf.keras.Model = user_model\n",
        "    self.task: tf.keras.layers.Layer = task\n",
        "\n",
        "  def compute_loss(self, features: Dict[Text, tf.Tensor], training=False) -> tf.Tensor:\n",
        "    # We pick out the user features and pass them into the user model.\n",
        "    user_embeddings = self.user_model(features[\"user_id\"])\n",
        "    # And pick out the movie features and pass them into the movie model,\n",
        "    # getting embeddings back.\n",
        "    positive_movie_embeddings = self.movie_model(features)\n",
        "\n",
        "    # The task computes the loss and the metrics.\n",
        "    return self.task(user_embeddings, positive_movie_embeddings)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5pJ8kow027M7"
      },
      "source": [
        "# Create a retrieval model.\n",
        "model = MovielensModel(user_model, movie_model, task)\n",
        "model.compile(optimizer=tf.keras.optimizers.Adagrad(0.01))"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wlKURaK-51HX"
      },
      "source": [
        "from keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
        "\n",
        "monitor_metric = \"val_total_loss\"\n",
        "\n",
        "reduce_lr = ReduceLROnPlateau(monitor=monitor_metric, factor=0.1, verbose=1,\n",
        "                                 patience=2)\n",
        "early_stop = EarlyStopping(monitor=monitor_metric, patience=4,\n",
        "                             verbose=1)\n",
        "callbacks = [reduce_lr, early_stop]"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0iTZoKAR3RkQ",
        "outputId": "a6c207e7-03f3-4505-d180-ca46161fc865"
      },
      "source": [
        "# Train for 3 epochs.\n",
        "model.fit(train_ratings.batch(10000), \n",
        "          epochs=50, \n",
        "          validation_data=test_ratings,\n",
        "          callbacks=callbacks)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "25/25 [==============================] - 14s 397ms/step - factorized_top_k/top_1_categorical_accuracy: 2.0000e-05 - factorized_top_k/top_5_categorical_accuracy: 0.0018 - factorized_top_k/top_10_categorical_accuracy: 0.0035 - factorized_top_k/top_50_categorical_accuracy: 0.0146 - factorized_top_k/top_100_categorical_accuracy: 0.0261 - loss: 33174.7934 - regularization_loss: 0.0000e+00 - total_loss: 33174.7934 - val_factorized_top_k/top_1_categorical_accuracy: 0.0019 - val_factorized_top_k/top_5_categorical_accuracy: 0.0088 - val_factorized_top_k/top_10_categorical_accuracy: 0.0140 - val_factorized_top_k/top_50_categorical_accuracy: 0.0368 - val_factorized_top_k/top_100_categorical_accuracy: 0.0557 - val_loss: 40714.3008 - val_regularization_loss: 0.0000e+00 - val_total_loss: 40714.3008\n",
            "Epoch 2/50\n",
            "25/25 [==============================] - 9s 377ms/step - factorized_top_k/top_1_categorical_accuracy: 1.0000e-05 - factorized_top_k/top_5_categorical_accuracy: 0.0153 - factorized_top_k/top_10_categorical_accuracy: 0.0253 - factorized_top_k/top_50_categorical_accuracy: 0.0604 - factorized_top_k/top_100_categorical_accuracy: 0.0849 - loss: 33153.3783 - regularization_loss: 0.0000e+00 - total_loss: 33153.3783 - val_factorized_top_k/top_1_categorical_accuracy: 0.0096 - val_factorized_top_k/top_5_categorical_accuracy: 0.0378 - val_factorized_top_k/top_10_categorical_accuracy: 0.0583 - val_factorized_top_k/top_50_categorical_accuracy: 0.1203 - val_factorized_top_k/top_100_categorical_accuracy: 0.1566 - val_loss: 40666.9883 - val_regularization_loss: 0.0000e+00 - val_total_loss: 40666.9883\n",
            "Epoch 3/50\n",
            "25/25 [==============================] - 9s 359ms/step - factorized_top_k/top_1_categorical_accuracy: 5.0000e-05 - factorized_top_k/top_5_categorical_accuracy: 0.0363 - factorized_top_k/top_10_categorical_accuracy: 0.0631 - factorized_top_k/top_50_categorical_accuracy: 0.1443 - factorized_top_k/top_100_categorical_accuracy: 0.1848 - loss: 33088.9369 - regularization_loss: 0.0000e+00 - total_loss: 33088.9369 - val_factorized_top_k/top_1_categorical_accuracy: 0.0148 - val_factorized_top_k/top_5_categorical_accuracy: 0.0626 - val_factorized_top_k/top_10_categorical_accuracy: 0.0968 - val_factorized_top_k/top_50_categorical_accuracy: 0.2015 - val_factorized_top_k/top_100_categorical_accuracy: 0.2500 - val_loss: 40552.5625 - val_regularization_loss: 0.0000e+00 - val_total_loss: 40552.5625\n",
            "Epoch 4/50\n",
            "25/25 [==============================] - 9s 351ms/step - factorized_top_k/top_1_categorical_accuracy: 5.0000e-05 - factorized_top_k/top_5_categorical_accuracy: 0.0548 - factorized_top_k/top_10_categorical_accuracy: 0.0930 - factorized_top_k/top_50_categorical_accuracy: 0.2052 - factorized_top_k/top_100_categorical_accuracy: 0.2576 - loss: 32980.6603 - regularization_loss: 0.0000e+00 - total_loss: 32980.6603 - val_factorized_top_k/top_1_categorical_accuracy: 0.0184 - val_factorized_top_k/top_5_categorical_accuracy: 0.0755 - val_factorized_top_k/top_10_categorical_accuracy: 0.1145 - val_factorized_top_k/top_50_categorical_accuracy: 0.2342 - val_factorized_top_k/top_100_categorical_accuracy: 0.2933 - val_loss: 40407.2617 - val_regularization_loss: 0.0000e+00 - val_total_loss: 40407.2617\n",
            "Epoch 5/50\n",
            "25/25 [==============================] - 9s 344ms/step - factorized_top_k/top_1_categorical_accuracy: 4.0000e-05 - factorized_top_k/top_5_categorical_accuracy: 0.0677 - factorized_top_k/top_10_categorical_accuracy: 0.1112 - factorized_top_k/top_50_categorical_accuracy: 0.2350 - factorized_top_k/top_100_categorical_accuracy: 0.2953 - loss: 32855.2405 - regularization_loss: 0.0000e+00 - total_loss: 32855.2405 - val_factorized_top_k/top_1_categorical_accuracy: 0.0224 - val_factorized_top_k/top_5_categorical_accuracy: 0.0893 - val_factorized_top_k/top_10_categorical_accuracy: 0.1299 - val_factorized_top_k/top_50_categorical_accuracy: 0.2534 - val_factorized_top_k/top_100_categorical_accuracy: 0.3152 - val_loss: 40260.8242 - val_regularization_loss: 0.0000e+00 - val_total_loss: 40260.8242\n",
            "Epoch 6/50\n",
            "25/25 [==============================] - 8s 338ms/step - factorized_top_k/top_1_categorical_accuracy: 4.0000e-05 - factorized_top_k/top_5_categorical_accuracy: 0.0774 - factorized_top_k/top_10_categorical_accuracy: 0.1215 - factorized_top_k/top_50_categorical_accuracy: 0.2483 - factorized_top_k/top_100_categorical_accuracy: 0.3118 - loss: 32732.0319 - regularization_loss: 0.0000e+00 - total_loss: 32732.0319 - val_factorized_top_k/top_1_categorical_accuracy: 0.0236 - val_factorized_top_k/top_5_categorical_accuracy: 0.0917 - val_factorized_top_k/top_10_categorical_accuracy: 0.1337 - val_factorized_top_k/top_50_categorical_accuracy: 0.2620 - val_factorized_top_k/top_100_categorical_accuracy: 0.3269 - val_loss: 40120.1562 - val_regularization_loss: 0.0000e+00 - val_total_loss: 40120.1562\n",
            "Epoch 7/50\n",
            "25/25 [==============================] - 9s 346ms/step - factorized_top_k/top_1_categorical_accuracy: 5.0000e-05 - factorized_top_k/top_5_categorical_accuracy: 0.0843 - factorized_top_k/top_10_categorical_accuracy: 0.1301 - factorized_top_k/top_50_categorical_accuracy: 0.2591 - factorized_top_k/top_100_categorical_accuracy: 0.3239 - loss: 32613.3828 - regularization_loss: 0.0000e+00 - total_loss: 32613.3828 - val_factorized_top_k/top_1_categorical_accuracy: 0.0252 - val_factorized_top_k/top_5_categorical_accuracy: 0.0963 - val_factorized_top_k/top_10_categorical_accuracy: 0.1376 - val_factorized_top_k/top_50_categorical_accuracy: 0.2637 - val_factorized_top_k/top_100_categorical_accuracy: 0.3303 - val_loss: 39995.9883 - val_regularization_loss: 0.0000e+00 - val_total_loss: 39995.9883\n",
            "Epoch 8/50\n",
            "25/25 [==============================] - 9s 341ms/step - factorized_top_k/top_1_categorical_accuracy: 7.0000e-05 - factorized_top_k/top_5_categorical_accuracy: 0.0880 - factorized_top_k/top_10_categorical_accuracy: 0.1338 - factorized_top_k/top_50_categorical_accuracy: 0.2620 - factorized_top_k/top_100_categorical_accuracy: 0.3283 - loss: 32505.1656 - regularization_loss: 0.0000e+00 - total_loss: 32505.1656 - val_factorized_top_k/top_1_categorical_accuracy: 0.0265 - val_factorized_top_k/top_5_categorical_accuracy: 0.1007 - val_factorized_top_k/top_10_categorical_accuracy: 0.1406 - val_factorized_top_k/top_50_categorical_accuracy: 0.2645 - val_factorized_top_k/top_100_categorical_accuracy: 0.3334 - val_loss: 39876.1094 - val_regularization_loss: 0.0000e+00 - val_total_loss: 39876.1094\n",
            "Epoch 9/50\n",
            "25/25 [==============================] - 8s 336ms/step - factorized_top_k/top_1_categorical_accuracy: 1.5000e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0933 - factorized_top_k/top_10_categorical_accuracy: 0.1387 - factorized_top_k/top_50_categorical_accuracy: 0.2668 - factorized_top_k/top_100_categorical_accuracy: 0.3341 - loss: 32405.3905 - regularization_loss: 0.0000e+00 - total_loss: 32405.3905 - val_factorized_top_k/top_1_categorical_accuracy: 0.0271 - val_factorized_top_k/top_5_categorical_accuracy: 0.1043 - val_factorized_top_k/top_10_categorical_accuracy: 0.1486 - val_factorized_top_k/top_50_categorical_accuracy: 0.2718 - val_factorized_top_k/top_100_categorical_accuracy: 0.3385 - val_loss: 39734.6172 - val_regularization_loss: 0.0000e+00 - val_total_loss: 39734.6172\n",
            "Epoch 10/50\n",
            "25/25 [==============================] - 9s 348ms/step - factorized_top_k/top_1_categorical_accuracy: 1.6000e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0938 - factorized_top_k/top_10_categorical_accuracy: 0.1396 - factorized_top_k/top_50_categorical_accuracy: 0.2694 - factorized_top_k/top_100_categorical_accuracy: 0.3385 - loss: 32307.4912 - regularization_loss: 0.0000e+00 - total_loss: 32307.4912 - val_factorized_top_k/top_1_categorical_accuracy: 0.0265 - val_factorized_top_k/top_5_categorical_accuracy: 0.1044 - val_factorized_top_k/top_10_categorical_accuracy: 0.1479 - val_factorized_top_k/top_50_categorical_accuracy: 0.2735 - val_factorized_top_k/top_100_categorical_accuracy: 0.3431 - val_loss: 39603.3945 - val_regularization_loss: 0.0000e+00 - val_total_loss: 39603.3945\n",
            "Epoch 11/50\n",
            "25/25 [==============================] - 9s 350ms/step - factorized_top_k/top_1_categorical_accuracy: 6.0000e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0955 - factorized_top_k/top_10_categorical_accuracy: 0.1421 - factorized_top_k/top_50_categorical_accuracy: 0.2718 - factorized_top_k/top_100_categorical_accuracy: 0.3428 - loss: 32221.8624 - regularization_loss: 0.0000e+00 - total_loss: 32221.8624 - val_factorized_top_k/top_1_categorical_accuracy: 0.0268 - val_factorized_top_k/top_5_categorical_accuracy: 0.1050 - val_factorized_top_k/top_10_categorical_accuracy: 0.1492 - val_factorized_top_k/top_50_categorical_accuracy: 0.2812 - val_factorized_top_k/top_100_categorical_accuracy: 0.3507 - val_loss: 39564.9102 - val_regularization_loss: 0.0000e+00 - val_total_loss: 39564.9102\n",
            "Epoch 12/50\n",
            "25/25 [==============================] - 9s 345ms/step - factorized_top_k/top_1_categorical_accuracy: 1.6000e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0960 - factorized_top_k/top_10_categorical_accuracy: 0.1433 - factorized_top_k/top_50_categorical_accuracy: 0.2764 - factorized_top_k/top_100_categorical_accuracy: 0.3484 - loss: 32135.8955 - regularization_loss: 0.0000e+00 - total_loss: 32135.8955 - val_factorized_top_k/top_1_categorical_accuracy: 0.0243 - val_factorized_top_k/top_5_categorical_accuracy: 0.1085 - val_factorized_top_k/top_10_categorical_accuracy: 0.1540 - val_factorized_top_k/top_50_categorical_accuracy: 0.2873 - val_factorized_top_k/top_100_categorical_accuracy: 0.3580 - val_loss: 39405.2188 - val_regularization_loss: 0.0000e+00 - val_total_loss: 39405.2188\n",
            "Epoch 13/50\n",
            "25/25 [==============================] - 9s 351ms/step - factorized_top_k/top_1_categorical_accuracy: 3.7000e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0955 - factorized_top_k/top_10_categorical_accuracy: 0.1444 - factorized_top_k/top_50_categorical_accuracy: 0.2790 - factorized_top_k/top_100_categorical_accuracy: 0.3519 - loss: 32055.4870 - regularization_loss: 0.0000e+00 - total_loss: 32055.4870 - val_factorized_top_k/top_1_categorical_accuracy: 0.0234 - val_factorized_top_k/top_5_categorical_accuracy: 0.1066 - val_factorized_top_k/top_10_categorical_accuracy: 0.1566 - val_factorized_top_k/top_50_categorical_accuracy: 0.2893 - val_factorized_top_k/top_100_categorical_accuracy: 0.3632 - val_loss: 39311.0117 - val_regularization_loss: 0.0000e+00 - val_total_loss: 39311.0117\n",
            "Epoch 14/50\n",
            "25/25 [==============================] - 9s 346ms/step - factorized_top_k/top_1_categorical_accuracy: 9.6000e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0959 - factorized_top_k/top_10_categorical_accuracy: 0.1461 - factorized_top_k/top_50_categorical_accuracy: 0.2828 - factorized_top_k/top_100_categorical_accuracy: 0.3573 - loss: 31971.7743 - regularization_loss: 0.0000e+00 - total_loss: 31971.7743 - val_factorized_top_k/top_1_categorical_accuracy: 0.0213 - val_factorized_top_k/top_5_categorical_accuracy: 0.1058 - val_factorized_top_k/top_10_categorical_accuracy: 0.1527 - val_factorized_top_k/top_50_categorical_accuracy: 0.2876 - val_factorized_top_k/top_100_categorical_accuracy: 0.3597 - val_loss: 39202.8867 - val_regularization_loss: 0.0000e+00 - val_total_loss: 39202.8867\n",
            "Epoch 15/50\n",
            "25/25 [==============================] - 9s 359ms/step - factorized_top_k/top_1_categorical_accuracy: 5.8000e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0966 - factorized_top_k/top_10_categorical_accuracy: 0.1479 - factorized_top_k/top_50_categorical_accuracy: 0.2851 - factorized_top_k/top_100_categorical_accuracy: 0.3598 - loss: 31898.7010 - regularization_loss: 0.0000e+00 - total_loss: 31898.7010 - val_factorized_top_k/top_1_categorical_accuracy: 0.0221 - val_factorized_top_k/top_5_categorical_accuracy: 0.1053 - val_factorized_top_k/top_10_categorical_accuracy: 0.1553 - val_factorized_top_k/top_50_categorical_accuracy: 0.2902 - val_factorized_top_k/top_100_categorical_accuracy: 0.3649 - val_loss: 39081.4375 - val_regularization_loss: 0.0000e+00 - val_total_loss: 39081.4375\n",
            "Epoch 16/50\n",
            "25/25 [==============================] - 9s 354ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0012 - factorized_top_k/top_5_categorical_accuracy: 0.0968 - factorized_top_k/top_10_categorical_accuracy: 0.1479 - factorized_top_k/top_50_categorical_accuracy: 0.2871 - factorized_top_k/top_100_categorical_accuracy: 0.3627 - loss: 31830.9578 - regularization_loss: 0.0000e+00 - total_loss: 31830.9578 - val_factorized_top_k/top_1_categorical_accuracy: 0.0215 - val_factorized_top_k/top_5_categorical_accuracy: 0.1081 - val_factorized_top_k/top_10_categorical_accuracy: 0.1588 - val_factorized_top_k/top_50_categorical_accuracy: 0.2937 - val_factorized_top_k/top_100_categorical_accuracy: 0.3669 - val_loss: 39010.7109 - val_regularization_loss: 0.0000e+00 - val_total_loss: 39010.7109\n",
            "Epoch 17/50\n",
            "25/25 [==============================] - 9s 351ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0011 - factorized_top_k/top_5_categorical_accuracy: 0.0965 - factorized_top_k/top_10_categorical_accuracy: 0.1499 - factorized_top_k/top_50_categorical_accuracy: 0.2912 - factorized_top_k/top_100_categorical_accuracy: 0.3677 - loss: 31748.5178 - regularization_loss: 0.0000e+00 - total_loss: 31748.5178 - val_factorized_top_k/top_1_categorical_accuracy: 0.0214 - val_factorized_top_k/top_5_categorical_accuracy: 0.1079 - val_factorized_top_k/top_10_categorical_accuracy: 0.1584 - val_factorized_top_k/top_50_categorical_accuracy: 0.3013 - val_factorized_top_k/top_100_categorical_accuracy: 0.3776 - val_loss: 38907.4961 - val_regularization_loss: 0.0000e+00 - val_total_loss: 38907.4961\n",
            "Epoch 18/50\n",
            "25/25 [==============================] - 9s 356ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0012 - factorized_top_k/top_5_categorical_accuracy: 0.0974 - factorized_top_k/top_10_categorical_accuracy: 0.1526 - factorized_top_k/top_50_categorical_accuracy: 0.2945 - factorized_top_k/top_100_categorical_accuracy: 0.3709 - loss: 31683.4109 - regularization_loss: 0.0000e+00 - total_loss: 31683.4109 - val_factorized_top_k/top_1_categorical_accuracy: 0.0221 - val_factorized_top_k/top_5_categorical_accuracy: 0.1084 - val_factorized_top_k/top_10_categorical_accuracy: 0.1610 - val_factorized_top_k/top_50_categorical_accuracy: 0.3027 - val_factorized_top_k/top_100_categorical_accuracy: 0.3808 - val_loss: 38823.4219 - val_regularization_loss: 0.0000e+00 - val_total_loss: 38823.4219\n",
            "Epoch 19/50\n",
            "25/25 [==============================] - 9s 350ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0019 - factorized_top_k/top_5_categorical_accuracy: 0.0965 - factorized_top_k/top_10_categorical_accuracy: 0.1523 - factorized_top_k/top_50_categorical_accuracy: 0.2969 - factorized_top_k/top_100_categorical_accuracy: 0.3743 - loss: 31611.7163 - regularization_loss: 0.0000e+00 - total_loss: 31611.7163 - val_factorized_top_k/top_1_categorical_accuracy: 0.0202 - val_factorized_top_k/top_5_categorical_accuracy: 0.1059 - val_factorized_top_k/top_10_categorical_accuracy: 0.1592 - val_factorized_top_k/top_50_categorical_accuracy: 0.3020 - val_factorized_top_k/top_100_categorical_accuracy: 0.3783 - val_loss: 38777.6211 - val_regularization_loss: 0.0000e+00 - val_total_loss: 38777.6211\n",
            "Epoch 20/50\n",
            "25/25 [==============================] - 9s 358ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0010 - factorized_top_k/top_5_categorical_accuracy: 0.0985 - factorized_top_k/top_10_categorical_accuracy: 0.1542 - factorized_top_k/top_50_categorical_accuracy: 0.2999 - factorized_top_k/top_100_categorical_accuracy: 0.3776 - loss: 31551.8631 - regularization_loss: 0.0000e+00 - total_loss: 31551.8631 - val_factorized_top_k/top_1_categorical_accuracy: 0.0211 - val_factorized_top_k/top_5_categorical_accuracy: 0.1084 - val_factorized_top_k/top_10_categorical_accuracy: 0.1620 - val_factorized_top_k/top_50_categorical_accuracy: 0.3047 - val_factorized_top_k/top_100_categorical_accuracy: 0.3841 - val_loss: 38695.4961 - val_regularization_loss: 0.0000e+00 - val_total_loss: 38695.4961\n",
            "Epoch 21/50\n",
            "25/25 [==============================] - 9s 351ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0016 - factorized_top_k/top_5_categorical_accuracy: 0.1000 - factorized_top_k/top_10_categorical_accuracy: 0.1563 - factorized_top_k/top_50_categorical_accuracy: 0.3034 - factorized_top_k/top_100_categorical_accuracy: 0.3821 - loss: 31485.5979 - regularization_loss: 0.0000e+00 - total_loss: 31485.5979 - val_factorized_top_k/top_1_categorical_accuracy: 0.0198 - val_factorized_top_k/top_5_categorical_accuracy: 0.1080 - val_factorized_top_k/top_10_categorical_accuracy: 0.1607 - val_factorized_top_k/top_50_categorical_accuracy: 0.3063 - val_factorized_top_k/top_100_categorical_accuracy: 0.3827 - val_loss: 38703.7031 - val_regularization_loss: 0.0000e+00 - val_total_loss: 38703.7031\n",
            "Epoch 22/50\n",
            "25/25 [==============================] - 9s 356ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0012 - factorized_top_k/top_5_categorical_accuracy: 0.0989 - factorized_top_k/top_10_categorical_accuracy: 0.1562 - factorized_top_k/top_50_categorical_accuracy: 0.3059 - factorized_top_k/top_100_categorical_accuracy: 0.3859 - loss: 31423.5856 - regularization_loss: 0.0000e+00 - total_loss: 31423.5856 - val_factorized_top_k/top_1_categorical_accuracy: 0.0202 - val_factorized_top_k/top_5_categorical_accuracy: 0.1082 - val_factorized_top_k/top_10_categorical_accuracy: 0.1612 - val_factorized_top_k/top_50_categorical_accuracy: 0.3038 - val_factorized_top_k/top_100_categorical_accuracy: 0.3834 - val_loss: 38644.3906 - val_regularization_loss: 0.0000e+00 - val_total_loss: 38644.3906\n",
            "Epoch 23/50\n",
            "25/25 [==============================] - 9s 350ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0018 - factorized_top_k/top_5_categorical_accuracy: 0.1001 - factorized_top_k/top_10_categorical_accuracy: 0.1573 - factorized_top_k/top_50_categorical_accuracy: 0.3066 - factorized_top_k/top_100_categorical_accuracy: 0.3863 - loss: 31369.3854 - regularization_loss: 0.0000e+00 - total_loss: 31369.3854 - val_factorized_top_k/top_1_categorical_accuracy: 0.0229 - val_factorized_top_k/top_5_categorical_accuracy: 0.1139 - val_factorized_top_k/top_10_categorical_accuracy: 0.1671 - val_factorized_top_k/top_50_categorical_accuracy: 0.3114 - val_factorized_top_k/top_100_categorical_accuracy: 0.3903 - val_loss: 38502.2695 - val_regularization_loss: 0.0000e+00 - val_total_loss: 38502.2695\n",
            "Epoch 24/50\n",
            "25/25 [==============================] - 9s 357ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0021 - factorized_top_k/top_5_categorical_accuracy: 0.1009 - factorized_top_k/top_10_categorical_accuracy: 0.1594 - factorized_top_k/top_50_categorical_accuracy: 0.3100 - factorized_top_k/top_100_categorical_accuracy: 0.3903 - loss: 31305.7118 - regularization_loss: 0.0000e+00 - total_loss: 31305.7118 - val_factorized_top_k/top_1_categorical_accuracy: 0.0225 - val_factorized_top_k/top_5_categorical_accuracy: 0.1113 - val_factorized_top_k/top_10_categorical_accuracy: 0.1652 - val_factorized_top_k/top_50_categorical_accuracy: 0.3095 - val_factorized_top_k/top_100_categorical_accuracy: 0.3902 - val_loss: 38489.6641 - val_regularization_loss: 0.0000e+00 - val_total_loss: 38489.6641\n",
            "Epoch 25/50\n",
            "25/25 [==============================] - 9s 354ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0019 - factorized_top_k/top_5_categorical_accuracy: 0.1014 - factorized_top_k/top_10_categorical_accuracy: 0.1600 - factorized_top_k/top_50_categorical_accuracy: 0.3122 - factorized_top_k/top_100_categorical_accuracy: 0.3931 - loss: 31255.9201 - regularization_loss: 0.0000e+00 - total_loss: 31255.9201 - val_factorized_top_k/top_1_categorical_accuracy: 0.0243 - val_factorized_top_k/top_5_categorical_accuracy: 0.1150 - val_factorized_top_k/top_10_categorical_accuracy: 0.1711 - val_factorized_top_k/top_50_categorical_accuracy: 0.3176 - val_factorized_top_k/top_100_categorical_accuracy: 0.3970 - val_loss: 38368.2578 - val_regularization_loss: 0.0000e+00 - val_total_loss: 38368.2578\n",
            "Epoch 26/50\n",
            "25/25 [==============================] - 9s 362ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0030 - factorized_top_k/top_5_categorical_accuracy: 0.1027 - factorized_top_k/top_10_categorical_accuracy: 0.1612 - factorized_top_k/top_50_categorical_accuracy: 0.3149 - factorized_top_k/top_100_categorical_accuracy: 0.3961 - loss: 31205.5327 - regularization_loss: 0.0000e+00 - total_loss: 31205.5327 - val_factorized_top_k/top_1_categorical_accuracy: 0.0253 - val_factorized_top_k/top_5_categorical_accuracy: 0.1143 - val_factorized_top_k/top_10_categorical_accuracy: 0.1705 - val_factorized_top_k/top_50_categorical_accuracy: 0.3192 - val_factorized_top_k/top_100_categorical_accuracy: 0.3980 - val_loss: 38356.7969 - val_regularization_loss: 0.0000e+00 - val_total_loss: 38356.7969\n",
            "Epoch 27/50\n",
            "25/25 [==============================] - 9s 353ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0028 - factorized_top_k/top_5_categorical_accuracy: 0.1030 - factorized_top_k/top_10_categorical_accuracy: 0.1620 - factorized_top_k/top_50_categorical_accuracy: 0.3155 - factorized_top_k/top_100_categorical_accuracy: 0.3969 - loss: 31153.6464 - regularization_loss: 0.0000e+00 - total_loss: 31153.6464 - val_factorized_top_k/top_1_categorical_accuracy: 0.0257 - val_factorized_top_k/top_5_categorical_accuracy: 0.1114 - val_factorized_top_k/top_10_categorical_accuracy: 0.1648 - val_factorized_top_k/top_50_categorical_accuracy: 0.3163 - val_factorized_top_k/top_100_categorical_accuracy: 0.3963 - val_loss: 38293.2969 - val_regularization_loss: 0.0000e+00 - val_total_loss: 38293.2969\n",
            "Epoch 28/50\n",
            "25/25 [==============================] - 9s 360ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0026 - factorized_top_k/top_5_categorical_accuracy: 0.1048 - factorized_top_k/top_10_categorical_accuracy: 0.1637 - factorized_top_k/top_50_categorical_accuracy: 0.3172 - factorized_top_k/top_100_categorical_accuracy: 0.3995 - loss: 31097.4419 - regularization_loss: 0.0000e+00 - total_loss: 31097.4419 - val_factorized_top_k/top_1_categorical_accuracy: 0.0272 - val_factorized_top_k/top_5_categorical_accuracy: 0.1159 - val_factorized_top_k/top_10_categorical_accuracy: 0.1701 - val_factorized_top_k/top_50_categorical_accuracy: 0.3185 - val_factorized_top_k/top_100_categorical_accuracy: 0.4025 - val_loss: 38227.8555 - val_regularization_loss: 0.0000e+00 - val_total_loss: 38227.8555\n",
            "Epoch 29/50\n",
            "25/25 [==============================] - 9s 354ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0027 - factorized_top_k/top_5_categorical_accuracy: 0.1055 - factorized_top_k/top_10_categorical_accuracy: 0.1643 - factorized_top_k/top_50_categorical_accuracy: 0.3189 - factorized_top_k/top_100_categorical_accuracy: 0.4016 - loss: 31050.7015 - regularization_loss: 0.0000e+00 - total_loss: 31050.7015 - val_factorized_top_k/top_1_categorical_accuracy: 0.0291 - val_factorized_top_k/top_5_categorical_accuracy: 0.1157 - val_factorized_top_k/top_10_categorical_accuracy: 0.1720 - val_factorized_top_k/top_50_categorical_accuracy: 0.3216 - val_factorized_top_k/top_100_categorical_accuracy: 0.4035 - val_loss: 38136.4336 - val_regularization_loss: 0.0000e+00 - val_total_loss: 38136.4336\n",
            "Epoch 30/50\n",
            "25/25 [==============================] - 9s 360ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0024 - factorized_top_k/top_5_categorical_accuracy: 0.1076 - factorized_top_k/top_10_categorical_accuracy: 0.1671 - factorized_top_k/top_50_categorical_accuracy: 0.3207 - factorized_top_k/top_100_categorical_accuracy: 0.4036 - loss: 31003.7513 - regularization_loss: 0.0000e+00 - total_loss: 31003.7513 - val_factorized_top_k/top_1_categorical_accuracy: 0.0299 - val_factorized_top_k/top_5_categorical_accuracy: 0.1208 - val_factorized_top_k/top_10_categorical_accuracy: 0.1757 - val_factorized_top_k/top_50_categorical_accuracy: 0.3242 - val_factorized_top_k/top_100_categorical_accuracy: 0.4064 - val_loss: 38095.2539 - val_regularization_loss: 0.0000e+00 - val_total_loss: 38095.2539\n",
            "Epoch 31/50\n",
            "25/25 [==============================] - 9s 353ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0023 - factorized_top_k/top_5_categorical_accuracy: 0.1079 - factorized_top_k/top_10_categorical_accuracy: 0.1672 - factorized_top_k/top_50_categorical_accuracy: 0.3222 - factorized_top_k/top_100_categorical_accuracy: 0.4058 - loss: 30951.2882 - regularization_loss: 0.0000e+00 - total_loss: 30951.2882 - val_factorized_top_k/top_1_categorical_accuracy: 0.0281 - val_factorized_top_k/top_5_categorical_accuracy: 0.1169 - val_factorized_top_k/top_10_categorical_accuracy: 0.1742 - val_factorized_top_k/top_50_categorical_accuracy: 0.3275 - val_factorized_top_k/top_100_categorical_accuracy: 0.4121 - val_loss: 38035.1250 - val_regularization_loss: 0.0000e+00 - val_total_loss: 38035.1250\n",
            "Epoch 32/50\n",
            "25/25 [==============================] - 9s 362ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0025 - factorized_top_k/top_5_categorical_accuracy: 0.1086 - factorized_top_k/top_10_categorical_accuracy: 0.1682 - factorized_top_k/top_50_categorical_accuracy: 0.3240 - factorized_top_k/top_100_categorical_accuracy: 0.4078 - loss: 30909.8132 - regularization_loss: 0.0000e+00 - total_loss: 30909.8132 - val_factorized_top_k/top_1_categorical_accuracy: 0.0338 - val_factorized_top_k/top_5_categorical_accuracy: 0.1215 - val_factorized_top_k/top_10_categorical_accuracy: 0.1784 - val_factorized_top_k/top_50_categorical_accuracy: 0.3285 - val_factorized_top_k/top_100_categorical_accuracy: 0.4106 - val_loss: 37973.6367 - val_regularization_loss: 0.0000e+00 - val_total_loss: 37973.6367\n",
            "Epoch 33/50\n",
            "25/25 [==============================] - 9s 355ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0021 - factorized_top_k/top_5_categorical_accuracy: 0.1105 - factorized_top_k/top_10_categorical_accuracy: 0.1698 - factorized_top_k/top_50_categorical_accuracy: 0.3250 - factorized_top_k/top_100_categorical_accuracy: 0.4096 - loss: 30863.7212 - regularization_loss: 0.0000e+00 - total_loss: 30863.7212 - val_factorized_top_k/top_1_categorical_accuracy: 0.0330 - val_factorized_top_k/top_5_categorical_accuracy: 0.1197 - val_factorized_top_k/top_10_categorical_accuracy: 0.1736 - val_factorized_top_k/top_50_categorical_accuracy: 0.3242 - val_factorized_top_k/top_100_categorical_accuracy: 0.4080 - val_loss: 37889.6328 - val_regularization_loss: 0.0000e+00 - val_total_loss: 37889.6328\n",
            "Epoch 34/50\n",
            "25/25 [==============================] - 9s 369ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0023 - factorized_top_k/top_5_categorical_accuracy: 0.1117 - factorized_top_k/top_10_categorical_accuracy: 0.1711 - factorized_top_k/top_50_categorical_accuracy: 0.3255 - factorized_top_k/top_100_categorical_accuracy: 0.4110 - loss: 30819.7250 - regularization_loss: 0.0000e+00 - total_loss: 30819.7250 - val_factorized_top_k/top_1_categorical_accuracy: 0.0346 - val_factorized_top_k/top_5_categorical_accuracy: 0.1221 - val_factorized_top_k/top_10_categorical_accuracy: 0.1770 - val_factorized_top_k/top_50_categorical_accuracy: 0.3293 - val_factorized_top_k/top_100_categorical_accuracy: 0.4140 - val_loss: 37877.4141 - val_regularization_loss: 0.0000e+00 - val_total_loss: 37877.4141\n",
            "Epoch 35/50\n",
            "25/25 [==============================] - 9s 364ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0030 - factorized_top_k/top_5_categorical_accuracy: 0.1132 - factorized_top_k/top_10_categorical_accuracy: 0.1728 - factorized_top_k/top_50_categorical_accuracy: 0.3282 - factorized_top_k/top_100_categorical_accuracy: 0.4139 - loss: 30778.9430 - regularization_loss: 0.0000e+00 - total_loss: 30778.9430 - val_factorized_top_k/top_1_categorical_accuracy: 0.0350 - val_factorized_top_k/top_5_categorical_accuracy: 0.1215 - val_factorized_top_k/top_10_categorical_accuracy: 0.1749 - val_factorized_top_k/top_50_categorical_accuracy: 0.3287 - val_factorized_top_k/top_100_categorical_accuracy: 0.4128 - val_loss: 37806.5781 - val_regularization_loss: 0.0000e+00 - val_total_loss: 37806.5781\n",
            "Epoch 36/50\n",
            "25/25 [==============================] - 9s 363ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0027 - factorized_top_k/top_5_categorical_accuracy: 0.1140 - factorized_top_k/top_10_categorical_accuracy: 0.1728 - factorized_top_k/top_50_categorical_accuracy: 0.3289 - factorized_top_k/top_100_categorical_accuracy: 0.4145 - loss: 30736.0291 - regularization_loss: 0.0000e+00 - total_loss: 30736.0291 - val_factorized_top_k/top_1_categorical_accuracy: 0.0362 - val_factorized_top_k/top_5_categorical_accuracy: 0.1241 - val_factorized_top_k/top_10_categorical_accuracy: 0.1794 - val_factorized_top_k/top_50_categorical_accuracy: 0.3305 - val_factorized_top_k/top_100_categorical_accuracy: 0.4160 - val_loss: 37680.6523 - val_regularization_loss: 0.0000e+00 - val_total_loss: 37680.6523\n",
            "Epoch 37/50\n",
            "25/25 [==============================] - 9s 361ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0023 - factorized_top_k/top_5_categorical_accuracy: 0.1142 - factorized_top_k/top_10_categorical_accuracy: 0.1743 - factorized_top_k/top_50_categorical_accuracy: 0.3300 - factorized_top_k/top_100_categorical_accuracy: 0.4160 - loss: 30695.1801 - regularization_loss: 0.0000e+00 - total_loss: 30695.1801 - val_factorized_top_k/top_1_categorical_accuracy: 0.0377 - val_factorized_top_k/top_5_categorical_accuracy: 0.1285 - val_factorized_top_k/top_10_categorical_accuracy: 0.1843 - val_factorized_top_k/top_50_categorical_accuracy: 0.3363 - val_factorized_top_k/top_100_categorical_accuracy: 0.4215 - val_loss: 37746.0664 - val_regularization_loss: 0.0000e+00 - val_total_loss: 37746.0664\n",
            "Epoch 38/50\n",
            "25/25 [==============================] - 10s 386ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0025 - factorized_top_k/top_5_categorical_accuracy: 0.1160 - factorized_top_k/top_10_categorical_accuracy: 0.1757 - factorized_top_k/top_50_categorical_accuracy: 0.3319 - factorized_top_k/top_100_categorical_accuracy: 0.4178 - loss: 30651.9234 - regularization_loss: 0.0000e+00 - total_loss: 30651.9234 - val_factorized_top_k/top_1_categorical_accuracy: 0.0376 - val_factorized_top_k/top_5_categorical_accuracy: 0.1238 - val_factorized_top_k/top_10_categorical_accuracy: 0.1816 - val_factorized_top_k/top_50_categorical_accuracy: 0.3348 - val_factorized_top_k/top_100_categorical_accuracy: 0.4196 - val_loss: 37747.1250 - val_regularization_loss: 0.0000e+00 - val_total_loss: 37747.1250\n",
            "\n",
            "Epoch 00038: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
            "Epoch 39/50\n",
            "25/25 [==============================] - 9s 357ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0036 - factorized_top_k/top_5_categorical_accuracy: 0.1174 - factorized_top_k/top_10_categorical_accuracy: 0.1775 - factorized_top_k/top_50_categorical_accuracy: 0.3348 - factorized_top_k/top_100_categorical_accuracy: 0.4211 - loss: 30618.6472 - regularization_loss: 0.0000e+00 - total_loss: 30618.6472 - val_factorized_top_k/top_1_categorical_accuracy: 0.0362 - val_factorized_top_k/top_5_categorical_accuracy: 0.1274 - val_factorized_top_k/top_10_categorical_accuracy: 0.1811 - val_factorized_top_k/top_50_categorical_accuracy: 0.3371 - val_factorized_top_k/top_100_categorical_accuracy: 0.4240 - val_loss: 37558.4531 - val_regularization_loss: 0.0000e+00 - val_total_loss: 37558.4531\n",
            "Epoch 40/50\n",
            "25/25 [==============================] - 9s 364ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0021 - factorized_top_k/top_5_categorical_accuracy: 0.1167 - factorized_top_k/top_10_categorical_accuracy: 0.1763 - factorized_top_k/top_50_categorical_accuracy: 0.3336 - factorized_top_k/top_100_categorical_accuracy: 0.4198 - loss: 30623.7760 - regularization_loss: 0.0000e+00 - total_loss: 30623.7760 - val_factorized_top_k/top_1_categorical_accuracy: 0.0368 - val_factorized_top_k/top_5_categorical_accuracy: 0.1227 - val_factorized_top_k/top_10_categorical_accuracy: 0.1789 - val_factorized_top_k/top_50_categorical_accuracy: 0.3315 - val_factorized_top_k/top_100_categorical_accuracy: 0.4177 - val_loss: 37689.4219 - val_regularization_loss: 0.0000e+00 - val_total_loss: 37689.4219\n",
            "Epoch 41/50\n",
            "25/25 [==============================] - 9s 359ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0031 - factorized_top_k/top_5_categorical_accuracy: 0.1169 - factorized_top_k/top_10_categorical_accuracy: 0.1772 - factorized_top_k/top_50_categorical_accuracy: 0.3334 - factorized_top_k/top_100_categorical_accuracy: 0.4196 - loss: 30619.4995 - regularization_loss: 0.0000e+00 - total_loss: 30619.4995 - val_factorized_top_k/top_1_categorical_accuracy: 0.0394 - val_factorized_top_k/top_5_categorical_accuracy: 0.1297 - val_factorized_top_k/top_10_categorical_accuracy: 0.1836 - val_factorized_top_k/top_50_categorical_accuracy: 0.3327 - val_factorized_top_k/top_100_categorical_accuracy: 0.4192 - val_loss: 37588.7031 - val_regularization_loss: 0.0000e+00 - val_total_loss: 37588.7031\n",
            "\n",
            "Epoch 00041: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n",
            "Epoch 42/50\n",
            "25/25 [==============================] - 9s 367ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0024 - factorized_top_k/top_5_categorical_accuracy: 0.1172 - factorized_top_k/top_10_categorical_accuracy: 0.1774 - factorized_top_k/top_50_categorical_accuracy: 0.3340 - factorized_top_k/top_100_categorical_accuracy: 0.4197 - loss: 30615.8706 - regularization_loss: 0.0000e+00 - total_loss: 30615.8706 - val_factorized_top_k/top_1_categorical_accuracy: 0.0376 - val_factorized_top_k/top_5_categorical_accuracy: 0.1272 - val_factorized_top_k/top_10_categorical_accuracy: 0.1842 - val_factorized_top_k/top_50_categorical_accuracy: 0.3394 - val_factorized_top_k/top_100_categorical_accuracy: 0.4242 - val_loss: 37726.2539 - val_regularization_loss: 0.0000e+00 - val_total_loss: 37726.2539\n",
            "Epoch 43/50\n",
            "25/25 [==============================] - 9s 361ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0027 - factorized_top_k/top_5_categorical_accuracy: 0.1181 - factorized_top_k/top_10_categorical_accuracy: 0.1782 - factorized_top_k/top_50_categorical_accuracy: 0.3353 - factorized_top_k/top_100_categorical_accuracy: 0.4214 - loss: 30611.0141 - regularization_loss: 0.0000e+00 - total_loss: 30611.0141 - val_factorized_top_k/top_1_categorical_accuracy: 0.0369 - val_factorized_top_k/top_5_categorical_accuracy: 0.1254 - val_factorized_top_k/top_10_categorical_accuracy: 0.1808 - val_factorized_top_k/top_50_categorical_accuracy: 0.3336 - val_factorized_top_k/top_100_categorical_accuracy: 0.4189 - val_loss: 37652.1992 - val_regularization_loss: 0.0000e+00 - val_total_loss: 37652.1992\n",
            "\n",
            "Epoch 00043: ReduceLROnPlateau reducing learning rate to 9.999999019782991e-06.\n",
            "Epoch 00043: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f6452d34e10>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "p-55FV-IEVIy",
        "outputId": "1829e580-e076-4b00-e0b2-71df6be47b87"
      },
      "source": [
        "lookup_user_id = \"151603712\"\n",
        "purchase_data[purchase_data[\"user_id\"] == lookup_user_id].head(5)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user_id</th>\n",
              "      <th>title</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>151603712</td>\n",
              "      <td>The Elder Scrolls V Skyrim</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>151603712</td>\n",
              "      <td>Fallout 4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>151603712</td>\n",
              "      <td>Spore</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>151603712</td>\n",
              "      <td>Fallout New Vegas</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>151603712</td>\n",
              "      <td>Left 4 Dead 2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     user_id                       title\n",
              "0  151603712  The Elder Scrolls V Skyrim\n",
              "2  151603712                   Fallout 4\n",
              "4  151603712                       Spore\n",
              "6  151603712           Fallout New Vegas\n",
              "8  151603712               Left 4 Dead 2"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9m7V8unu3T2W",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f58d1161-2625-4347-a4fd-16ac853fe137"
      },
      "source": [
        "# Use brute-force search to set up retrieval using the trained representations.\n",
        "index = tfrs.layers.factorized_top_k.BruteForce(model.user_model)\n",
        "index.index(movies.map(lambda x: {\"movie_title\": x}).map(model.movie_model), movies)\n",
        "\n",
        "# Get some recommendations.\n",
        "_, titles = index(np.array([lookup_user_id]))\n",
        "print(f\"Top 3 recommendations for user {lookup_user_id}: {titles[0, :3]}\")"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Top 3 recommendations for user 42: [b'The Elder Scrolls V Skyrim - Dragonborn'\n",
            " b'The Elder Scrolls V Skyrim - Dawnguard'\n",
            " b'The Elder Scrolls V Skyrim - Hearthfire']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hc53t3YmDU-h"
      },
      "source": [
        ""
      ],
      "execution_count": 22,
      "outputs": []
    }
  ]
}